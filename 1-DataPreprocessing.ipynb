{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\anaconda\\envs\\ptgpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from glob import glob\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AlzheimerDataset(Dataset):\n",
    "    def __init__(self, images_filepaths, transform=None):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.images_filepaths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if os.path.normpath(image_filepath).split(os.sep)[-2] == \"Mild_Demented\":\n",
    "            label = 0\n",
    "        elif os.path.normpath(image_filepath).split(os.sep)[-2] == \"Moderate_Demented\":\n",
    "            label=1\n",
    "        elif os.path.normpath(image_filepath).split(os.sep)[-2] == \"Non_Demented\":\n",
    "            label=2\n",
    "        else:\n",
    "            label = 3\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install split-folders (记得安装)\n",
    "import splitfolders\n",
    "\n",
    "path='./Dataset'\n",
    "splitfolders.ratio(path,ratio=(0.7,0.3,0))\n",
    "# 拆分训练集,验证集，测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将train，validation的数据保存到output文件夹\n",
    "datasets={\n",
    "        'train':[],\n",
    "        'val':[]\n",
    "    }\n",
    "for phase in ['train','val']:\n",
    "    l=[]\n",
    "    for i in glob(f'./output/{phase}/**/*'):\n",
    "        l.append(i)\n",
    "    datasets[phase]=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 4479, 'val': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对数据进行Augmentation处理\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=128, width=128),  # 调整图像大小为 128x128\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),  # 随机平移、缩放和旋转\n",
    "        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),  # 随机RGB通道偏移\n",
    "        A.RandomBrightnessContrast(p=0.5),  # 随机亮度和对比度调整\n",
    "        A.ColorJitter(),  # 随机色彩抖动\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # 标准化\n",
    "        ToTensorV2(),  # 转换为PyTorch张量\n",
    "    ]\n",
    ")\n",
    "\n",
    "original_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(128, 128),  # 调整图像大小为 128x128\n",
    "        A.CenterCrop(height=128, width=128),  # 中心裁剪\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # 标准化\n",
    "        ToTensorV2(),  # 转换为PyTorch张量\n",
    "    ]\n",
    ")\n",
    "\n",
    "#创建实例\n",
    "alb_dataset = AlzheimerDataset(images_filepaths=datasets['train'], transform=train_transform)\n",
    "original_dataset=AlzheimerDataset(images_filepaths=datasets['train'], transform=original_transform)\n",
    "\n",
    "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val']}\n",
    "class_names = ['Mild_Demented','Moderate_Demented','Non_Demented','Very_Mild_Demented']\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files exist\n"
     ]
    }
   ],
   "source": [
    "#保存augmentation处理后的数据于predata文件夹\n",
    "import uuid\n",
    "try:\n",
    "    os.mkdir('./prepdata')\n",
    "    os.mkdir('./prepdata/train')\n",
    "    os.mkdir('./prepdata/train/Mild_Demented')\n",
    "    os.mkdir('./prepdata/train/Moderate_Demented')\n",
    "    os.mkdir('./prepdata/train/Non_Demented')\n",
    "    os.mkdir('./prepdata/train/Very_Mild_Demented')\n",
    "    \n",
    "except:\n",
    "    print('Files exist')\n",
    "\n",
    "def OriginalSave(originalDataset,limit):\n",
    "    s={0:'Mild_Demented',1:'Moderate_Demented',2:'Non_Demented',3:'Very_Mild_Demented'}\n",
    "    originalDataset.transform = A.Compose([t for t in originalDataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n",
    "    \n",
    "    for idx in range(limit):\n",
    "        image,label=originalDataset[idx]\n",
    "\n",
    "        cv2.imwrite(f'./prepdata/{s[label]}/{str(uuid.uuid4())}.jpg',image)\n",
    "OriginalSave(original_dataset, dataset_sizes['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 28\u001B[0m\n\u001B[0;32m     25\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m label\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m3\u001B[39m:\n\u001B[0;32m     26\u001B[0m                 cv2\u001B[38;5;241m.\u001B[39mimwrite(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./prepdata/train/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00ms[label]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(uuid\u001B[38;5;241m.\u001B[39muuid4())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m,image)\n\u001B[1;32m---> 28\u001B[0m \u001B[43mAlbSave\u001B[49m\u001B[43m(\u001B[49m\u001B[43malb_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdataset_sizes\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[7], line 14\u001B[0m, in \u001B[0;36mAlbSave\u001B[1;34m(albDataset, limit)\u001B[0m\n\u001B[0;32m     11\u001B[0m         cv2\u001B[38;5;241m.\u001B[39mimwrite(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./prepdata/train/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00ms[label]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(uuid\u001B[38;5;241m.\u001B[39muuid4())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m,image)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m100\u001B[39m):\n\u001B[1;32m---> 14\u001B[0m     image,label\u001B[38;5;241m=\u001B[39m\u001B[43malbDataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m label\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m     16\u001B[0m         cv2\u001B[38;5;241m.\u001B[39mimwrite(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./prepdata/train/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00ms[label]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(uuid\u001B[38;5;241m.\u001B[39muuid4())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m,image)\n",
      "Cell \u001B[1;32mIn[3], line 25\u001B[0m, in \u001B[0;36mAlzheimerDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     23\u001B[0m     label \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 25\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m image, label\n",
      "File \u001B[1;32mf:\\anaconda\\envs\\ptgpu\\lib\\site-packages\\albumentations\\core\\composition.py:307\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, force_apply, *args, **data)\u001B[0m\n\u001B[0;32m    304\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(data)\n\u001B[0;32m    306\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m--> 307\u001B[0m     data \u001B[38;5;241m=\u001B[39m t(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdata)\n\u001B[0;32m    308\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_data_post_transform(data)\n\u001B[0;32m    310\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpostprocess(data)\n",
      "File \u001B[1;32mf:\\anaconda\\envs\\ptgpu\\lib\\site-packages\\albumentations\\core\\transforms_interface.py:123\u001B[0m, in \u001B[0;36mBasicTransform.__call__\u001B[1;34m(self, force_apply, *args, **kwargs)\u001B[0m\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdeterministic:\n\u001B[0;32m    122\u001B[0m         kwargs[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_key][\u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m)] \u001B[38;5;241m=\u001B[39m deepcopy(params)\n\u001B[1;32m--> 123\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_with_params(params, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    125\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m kwargs\n",
      "File \u001B[1;32mf:\\anaconda\\envs\\ptgpu\\lib\\site-packages\\albumentations\\core\\transforms_interface.py:135\u001B[0m, in \u001B[0;36mBasicTransform.apply_with_params\u001B[1;34m(self, params, *args, **kwargs)\u001B[0m\n\u001B[0;32m    133\u001B[0m target_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_key2func[key]\n\u001B[0;32m    134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arg, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[1;32m--> 135\u001B[0m     result \u001B[38;5;241m=\u001B[39m target_function(np\u001B[38;5;241m.\u001B[39mrequire(arg, requirements\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC_CONTIGUOUS\u001B[39m\u001B[38;5;124m\"\u001B[39m]), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[0;32m    136\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m    137\u001B[0m         res[key] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrequire(result, requirements\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC_CONTIGUOUS\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[1;32mf:\\anaconda\\envs\\ptgpu\\lib\\site-packages\\albumentations\\augmentations\\geometric\\transforms.py:715\u001B[0m, in \u001B[0;36mAffine.apply\u001B[1;34m(self, img, matrix, output_shape, **params)\u001B[0m\n\u001B[0;32m    708\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m    709\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    710\u001B[0m     img: np\u001B[38;5;241m.\u001B[39mndarray,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    713\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams: Any,\n\u001B[0;32m    714\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[1;32m--> 715\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfgeometric\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwarp_affine\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    716\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    717\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmatrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    718\u001B[0m \u001B[43m        \u001B[49m\u001B[43minterpolation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    719\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    720\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    721\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_shape\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    722\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mf:\\anaconda\\envs\\ptgpu\\lib\\site-packages\\albucore\\utils.py:113\u001B[0m, in \u001B[0;36mpreserve_channel_dim.<locals>.wrapped_function\u001B[1;34m(img, *args, **kwargs)\u001B[0m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_function\u001B[39m(img: np\u001B[38;5;241m.\u001B[39mndarray, \u001B[38;5;241m*\u001B[39margs: P\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: P\u001B[38;5;241m.\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[0;32m    112\u001B[0m     shape \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m--> 113\u001B[0m     result \u001B[38;5;241m=\u001B[39m func(img, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(shape) \u001B[38;5;241m==\u001B[39m NUM_MULTI_CHANNEL_DIMENSIONS \u001B[38;5;129;01mand\u001B[39;00m shape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m result\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m MONO_CHANNEL_DIMENSIONS:\n\u001B[0;32m    115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mexpand_dims(result, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32mf:\\anaconda\\envs\\ptgpu\\lib\\site-packages\\albumentations\\augmentations\\geometric\\functional.py:538\u001B[0m, in \u001B[0;36mwarp_affine\u001B[1;34m(image, matrix, interpolation, cval, mode, output_shape)\u001B[0m\n\u001B[0;32m    529\u001B[0m dsize \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(np\u001B[38;5;241m.\u001B[39mround(output_shape[\u001B[38;5;241m1\u001B[39m])), \u001B[38;5;28mint\u001B[39m(np\u001B[38;5;241m.\u001B[39mround(output_shape[\u001B[38;5;241m0\u001B[39m]))\n\u001B[0;32m    530\u001B[0m warp_fn \u001B[38;5;241m=\u001B[39m maybe_process_in_chunks(\n\u001B[0;32m    531\u001B[0m     warp_affine_with_value_extension,\n\u001B[0;32m    532\u001B[0m     matrix\u001B[38;5;241m=\u001B[39mmatrix\u001B[38;5;241m.\u001B[39mparams[:\u001B[38;5;241m2\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    536\u001B[0m     border_value\u001B[38;5;241m=\u001B[39mcval,\n\u001B[0;32m    537\u001B[0m )\n\u001B[1;32m--> 538\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwarp_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mf:\\anaconda\\envs\\ptgpu\\lib\\site-packages\\albucore\\utils.py:86\u001B[0m, in \u001B[0;36mmaybe_process_in_chunks.<locals>.__process_fn\u001B[1;34m(img)\u001B[0m\n\u001B[0;32m     83\u001B[0m             chunks\u001B[38;5;241m.\u001B[39mappend(chunk)\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mdstack(chunks)\n\u001B[1;32m---> 86\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m process_fn(img, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mf:\\anaconda\\envs\\ptgpu\\lib\\site-packages\\albumentations\\augmentations\\geometric\\functional.py:507\u001B[0m, in \u001B[0;36mwarp_affine_with_value_extension\u001B[1;34m(image, matrix, dsize, flags, border_mode, border_value)\u001B[0m\n\u001B[0;32m    504\u001B[0m num_channels \u001B[38;5;241m=\u001B[39m get_num_channels(image)\n\u001B[0;32m    505\u001B[0m extended_value \u001B[38;5;241m=\u001B[39m extend_value(border_value, num_channels)\n\u001B[1;32m--> 507\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwarpAffine\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[43m    \u001B[49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    509\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmatrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    510\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdsize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    511\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mflags\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    512\u001B[0m \u001B[43m    \u001B[49m\u001B[43mborderMode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mborder_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    513\u001B[0m \u001B[43m    \u001B[49m\u001B[43mborderValue\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    514\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# balance data\n",
    "def AlbSave(albDataset,limit):\n",
    "    s={0:'Mild_Demented',1:'Moderate_Demented',2:'Non_Demented',3:'Very_Mild_Demented'}\n",
    "    sizes={'Mild_Demented':896,'Moderate_Demented':64,'Non_Demented':3200,'Very_Mild_Demented':2240}\n",
    "\n",
    "    albDataset.transform = A.Compose([t for t in albDataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n",
    "    for idx in range(limit):\n",
    "        for _ in range(7):\n",
    "            image,label=albDataset[idx]\n",
    "            if label==0:\n",
    "                cv2.imwrite(f'./prepdata/train/{s[label]}/{str(uuid.uuid4())}.jpg',image)\n",
    "\n",
    "        for _ in range(100):\n",
    "            image,label=albDataset[idx]\n",
    "            if label==1:\n",
    "                cv2.imwrite(f'./prepdata/train/{s[label]}/{str(uuid.uuid4())}.jpg',image)\n",
    "\n",
    "        for _ in range(2):\n",
    "            image,label=albDataset[idx]\n",
    "            if label==2:\n",
    "                cv2.imwrite(f'./prepdata/train/{s[label]}/{str(uuid.uuid4())}.jpg',image)\n",
    "                \n",
    "        for _ in range(3):\n",
    "            image,label=albDataset[idx]\n",
    "            if label==3:\n",
    "                cv2.imwrite(f'./prepdata/train/{s[label]}/{str(uuid.uuid4())}.jpg',image)\n",
    "\n",
    "AlbSave(alb_dataset,dataset_sizes['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Destination path './prepdata/val' already exists",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mError\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#不对验证集进行augmentation处理\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mshutil\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[43mshutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmove\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./output/val\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./prepdata/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mf:\\anaconda\\envs\\ptgpu\\lib\\shutil.py:814\u001B[0m, in \u001B[0;36mmove\u001B[1;34m(src, dst, copy_function)\u001B[0m\n\u001B[0;32m    811\u001B[0m     real_dst \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(dst, _basename(src))\n\u001B[0;32m    813\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(real_dst):\n\u001B[1;32m--> 814\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Error(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDestination path \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m already exists\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m real_dst)\n\u001B[0;32m    815\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    816\u001B[0m     os\u001B[38;5;241m.\u001B[39mrename(src, real_dst)\n",
      "\u001B[1;31mError\u001B[0m: Destination path './prepdata/val' already exists"
     ]
    }
   ],
   "source": [
    "#不对验证集进行augmentation处理\n",
    "import shutil\n",
    "shutil.move('./output/val','./prepdata/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}